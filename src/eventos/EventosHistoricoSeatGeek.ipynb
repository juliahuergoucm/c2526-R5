{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03655ab2-db44-4327-aeab-dea930cf6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "BASE_URL = \"https://api.seatgeek.com/2/events\"\n",
    "\n",
    "def fetch_page(\n",
    "    client_id: str,\n",
    "    start_utc: str,\n",
    "    end_utc: str,\n",
    "    page: int,\n",
    "    per_page: int = 100,\n",
    "    extra_params: Optional[Dict[str, Any]] = None,\n",
    "    max_retries: int = 5,\n",
    "    backoff_seconds: float = 1.5,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Descarga una página de eventos usando filtros por datetime_utc y paginación.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"client_id\": client_id,\n",
    "        \"page\": page,\n",
    "        \"per_page\": per_page,\n",
    "        \"datetime_utc.gte\": start_utc,\n",
    "        \"datetime_utc.lte\": end_utc,\n",
    "    }\n",
    "    if extra_params:\n",
    "        params.update(extra_params)\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            r = requests.get(BASE_URL, params=params, timeout=30)\n",
    "\n",
    "            if r.status_code in (429, 502, 503, 504):\n",
    "                sleep_s = backoff_seconds * attempt\n",
    "                time.sleep(sleep_s)\n",
    "                continue\n",
    "\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(backoff_seconds * attempt)\n",
    "\n",
    "    raise RuntimeError(f\"Fallo descargando page={page}. Último error: {last_err}\")\n",
    "\n",
    "\n",
    "def extract_events_2025(\n",
    "    client_id: str,\n",
    "    out_json_path: str = \"seatgeek_events_2025.json\",\n",
    "    out_csv_path: str = \"seatgeek_events_2025.csv\",\n",
    "    per_page: int = 100,\n",
    "):\n",
    "    # 2025-01-01 hasta fin de año\n",
    "    start_utc = \"2025-01-01T00:00:00\"\n",
    "    end_utc = \"2025-12-31T23:59:59\"\n",
    "\n",
    "    all_events: List[Dict[str, Any]] = []\n",
    "\n",
    "    # Primera pagina para saber el total\n",
    "    first = fetch_page(\n",
    "        client_id=client_id,\n",
    "        start_utc=start_utc,\n",
    "        end_utc=end_utc,\n",
    "        page=1,\n",
    "        per_page=per_page,\n",
    "    )\n",
    "\n",
    "    meta = first.get(\"meta\", {}) or {}\n",
    "    total = meta.get(\"total\", 0) or 0\n",
    "    total_pages = int(math.ceil(total / per_page)) if total else 1\n",
    "\n",
    "    events = first.get(\"events\", []) or []\n",
    "    all_events.extend(events)\n",
    "\n",
    "    print(f\"Total eventos (según meta.total): {total}\")\n",
    "    print(f\"Páginas estimadas: {total_pages} (per_page={per_page})\")\n",
    "    print(f\"Página 1 -> eventos: {len(events)}\")\n",
    "\n",
    "    # Itero sobre el resto de pags\n",
    "    for page in range(2, total_pages + 1):\n",
    "        data = fetch_page(\n",
    "            client_id=client_id,\n",
    "            start_utc=start_utc,\n",
    "            end_utc=end_utc,\n",
    "            page=page,\n",
    "            per_page=per_page,\n",
    "        )\n",
    "        events = data.get(\"events\", []) or []\n",
    "        all_events.extend(events)\n",
    "        print(f\"Página {page} -> eventos: {len(events)} (acumulados: {len(all_events)})\")\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # Guardo el JSON\n",
    "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_events, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 4) Guardo CSV con los campos utiles\n",
    "    rows = []\n",
    "    for ev in all_events:\n",
    "        venue = ev.get(\"venue\") or {}\n",
    "        performers = ev.get(\"performers\") or []\n",
    "        rows.append({\n",
    "            \"id\": ev.get(\"id\"),\n",
    "            \"title\": ev.get(\"title\"),\n",
    "            \"type\": ev.get(\"type\"),\n",
    "            \"datetime_utc\": ev.get(\"datetime_utc\"),\n",
    "            \"url\": ev.get(\"url\"),\n",
    "            \"score\": ev.get(\"score\"),\n",
    "            \"venue_name\": venue.get(\"name\"),\n",
    "            \"venue_city\": venue.get(\"city\"),\n",
    "            \"venue_state\": venue.get(\"state\"),\n",
    "            \"venue_country\": venue.get(\"country\"),\n",
    "            \"venue_lat\": venue.get(\"lat\"),\n",
    "            \"venue_lon\": venue.get(\"lon\"),\n",
    "            \"performers\": \", \".join([p.get(\"name\", \"\") for p in performers if p.get(\"name\")]),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\n Listo\")\n",
    "    print(f\"- JSON: {out_json_path} ({len(all_events)} eventos)\")\n",
    "    print(f\"- CSV:  {out_csv_path} ({len(df)} filas)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    client_id = os.getenv(\"SEATGEEK_CLIENT_ID\")\n",
    "    \n",
    "    if not client_id:\n",
    "        raise SystemExit(\"❌ Falta SEATGEEK_CLIENT_ID. Define la variable de entorno o pega el client_id en el script.\")\n",
    "\n",
    "    extract_events_2025(client_id=client_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda]",
   "language": "python",
   "name": "conda-env-Anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
